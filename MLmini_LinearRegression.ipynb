{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLmini-LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNT0/urB4q9qfwcIjb4yyai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearningMiniCourse/blob/master/MLmini_LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXO2Fa0YBjB5",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *mini* Course\n",
        "### PythonChallenge.ir\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "\n",
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IljETY4yFS5a",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The theoretical stuff has been discussed in the video lectures. Let's implement a little...\n",
        "\n",
        "First of all, we should import some modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9sWGnzX1xNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOo1VsyEBkcZ",
        "colab_type": "text"
      },
      "source": [
        "# Creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ltTDTTAn5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([np.linspace(10, 50, 15)])\n",
        "y = 2 + 1.5 * x +  10 * np.random.normal(0, 1, x.shape)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7hZL_JhBuIZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-SKelkBFx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x, y, 'rx')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAdoekrHBxhi",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression (Hand Coding!)\n",
        "Now, we implement our estimator just using **numpy**. In this method, we implement gradients calculation and weight updates (gradient descent) by hand!\n",
        "\n",
        "Let's implement estimator (hypothesis) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNAw7Z2pBdJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def h(x, w):\n",
        "  x = np.concatenate((np.ones((1, x.shape[1])) ,x))\n",
        "  return np.dot(np.transpose(x), w)\n",
        "\n",
        "w = np.array([[1], [0.5]])\n",
        "print(h(np.array([[1]]), w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiftUlS5Hd3R",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Data and Estimator Result\n",
        "It is exciting to see the performance with a simple function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3adT50oHsab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(x, y, w):\n",
        "  predicted = np.transpose(h(x, w))\n",
        "  plt.figure()\n",
        "  plt.plot(x, y, 'rx')\n",
        "  plt.plot(x, predicted, 'bo')\n",
        "  plt.show()\n",
        "\n",
        "w = np.array([[1.88], [1.54]])\n",
        "show(x, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN6ilNiRCavp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.0001\n",
        "\n",
        "def train_step(x, y, w):\n",
        "  delta_w = -np.dot(x, np.transpose(y) - h(x, w))\n",
        "  w = w - alpha * delta_w\n",
        "  return w\n",
        "\n",
        "def cost(x, y, w):\n",
        "  return float(np.dot(np.transpose(np.transpose(y) - h(x, w)), np.transpose(y) - h(x, w)) / (2*y.shape[1]))\n",
        "\n",
        "def train(x, y, max_iters=1000, min_cost=0.1, w=None, verbose=0):\n",
        "  if w is None:\n",
        "    w = np.random.rand(2, 1)\n",
        "  for i in range(max_iters):\n",
        "    index = np.random.randint(0, x.shape[1])\n",
        "    w = train_step(x[:, index:index+1], y[:, index:index+1], w)\n",
        "    if cost(x, y, w) < min_cost:\n",
        "      break\n",
        "    if verbose:\n",
        "      print('Iteration {}: W = '.format(i+1),np.transpose(w), 'Cost = ', cost(x, y, w))\n",
        "  print(\"Training Done...\")\n",
        "  print(\"Cost: {}\".format(cost(x, y, w)))\n",
        "  print(\"w = \", w.T)\n",
        "  return w\n",
        "\n",
        "w = train(x, y, max_iters=1000, min_cost=10 ,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRuSuINcL8MF",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Performance\n",
        "Let's see the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bMbot_eL7iX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(x.shape[1]):\n",
        "  print('Input: {}, Target: {}, Output: {}'.format(np.transpose(x[:,i:i+1]), np.transpose(y[:, i:i+1]), np.transpose(h(x[:, i:i+1], w))))\n",
        "\n",
        "show(x, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj3QFgizKZKR",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression (Using Tensorflow 2)\n",
        "Now let's use **tensorflow**. Some benefits of using tensorflow:\n",
        "\n",
        "\n",
        "*   We can create more complex models in it without doing some theory stuff like finding gradients by hand!\n",
        "*   Using some amazing optimizers.\n",
        "*   Extensive use in deep learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwnh2pvpPNZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.constant(x, dtype=tf.float32)\n",
        "Y = tf.constant(y, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRUg72z3O43w",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Data and Estimator Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpgMF_vkO5rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_show(x, y, w):\n",
        "  predicted = tf.transpose(tf_h(x, w))\n",
        "  plt.figure()\n",
        "  plt.plot(x, y, 'rx')\n",
        "  plt.plot(x, predicted, 'bo')\n",
        "  plt.show()\n",
        "\n",
        "W = tf.Variable(np.random.rand(2, 1), dtype=tf.float32)\n",
        "tf_show(X, Y, W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTYWdPqeV7Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "def tf_h(x, w):\n",
        "  x = tf.concat((tf.ones((1, x.shape[1])), x), 0)\n",
        "  return tf.matmul(x, w, True)\n",
        "\n",
        "def tf_loss(x, y, w):\n",
        "  c = y - tf_h(x, w)\n",
        "  return tf.matmul(c, c, True)\n",
        "\n",
        "def tf_cost(X, Y, W):\n",
        "  a = tf.transpose(Y) - tf_h(X, W)\n",
        "  return tf.matmul(a, a, True)/(2*X.shape[1])\n",
        "\n",
        "def tf_train_step(x, y, w, verbose=0):\n",
        "  with tf.GradientTape() as t:\n",
        "    J = tf_loss(x, y, w)\n",
        "    if verbose:\n",
        "      print('Loss: ',J)\n",
        "  w_grads = t.gradient(J, w)\n",
        "  optimizer.apply_gradients(zip([w_grads], [w]))\n",
        "  return w\n",
        "\n",
        "def tf_train(X, Y, max_iters=1000, min_cost=0.01, W=None, verbose=0):\n",
        "  if W is None:\n",
        "    W = tf.Variable(np.random.rand(2, 1), dtype=tf.float32)\n",
        "  for i in range(max_iters):\n",
        "    index = np.random.randint(0, x.shape[1])\n",
        "    tf_train_step(X[:, index:index+1], Y[:, index:index+1], W)\n",
        "    cost_value = tf_cost(X, Y, W).numpy()[0][0]\n",
        "    if verbose:\n",
        "      print('Cost: ', cost_value)\n",
        "    if cost_value < min_cost:\n",
        "      break\n",
        "  print(\"Training Done...\")\n",
        "  print(\"Cost: {}\".format(tf_cost(X, Y, W).numpy()[0][0]))\n",
        "  print(\"W = \", W)\n",
        "  return W\n",
        "  \n",
        "W = tf.Variable(np.random.rand(2, 1), dtype=tf.float32)\n",
        "index = np.random.randint(0, x.shape[1])\n",
        "print('Before: ', W.numpy().T)\n",
        "tf_train_step(X[:, index:index+1], Y[:, index:index+1], W)\n",
        "print('After: ', W.numpy().T)\n",
        "print('Cost: ', tf_cost(X, Y, W).numpy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHqRgHjDB25j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf_train(X, Y, W=W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_WEIsVNOs-M",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAwB3uEd98Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_show(X, Y, W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eueXTkNhovJj",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression (Normal Equation)\n",
        "\n",
        "Use of normal equation, where possible, makes our life a lot easier!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXrL2aZbqgof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.shape, y.shape)\n",
        "x1 = np.concatenate((np.ones((1, x.shape[1])), x))\n",
        "print(x1.shape)\n",
        "x1 = np.transpose(x1)\n",
        "y1 = np.transpose(y)\n",
        "w = np.dot(np.dot(np.linalg.inv(np.dot(x1.T, x1)), x1.T), y1)\n",
        "print(w)\n",
        "show(x, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib5RbrFISRtp",
        "colab_type": "text"
      },
      "source": [
        "# California Housing Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCylJszSVGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = pd.read_csv('sample_data/california_housing_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p19N6Rx_S3KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCrLBUbvUpBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(ds.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByAIN8G5XJ7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojGCW_8fXY-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = ds.mean()\n",
        "s = ds.std()\n",
        "print('Mean:\\n', m)\n",
        "print('Standard Deviation:\\n', s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okC6P9wyl7g5",
        "colab_type": "text"
      },
      "source": [
        "## Method 1\n",
        "In this method, we simply load the dataset and convert it to *tensors*. After that our life is made easy! we just use the previous functions we implemented by tensorflow.\n",
        "\n",
        "Now we separate inputs from targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGa6IyjamNht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_arr = np.transpose(np.array(ds))\n",
        "y = ds_arr[-1:, :]\n",
        "X = ds_arr[:-1, :]\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGucHyTroL9S",
        "colab_type": "text"
      },
      "source": [
        "Converting data to *tensors*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5rhbem-mQ9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.constant(X, dtype=tf.float32)\n",
        "y = tf.constant(y, dtype=tf.float32)\n",
        "W = tf.Variable(np.random.rand(X.shape[0]+1, 1), dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfDwzSNhoSLY",
        "colab_type": "text"
      },
      "source": [
        "Let's do the training now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54V6ohvWmW8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf_train(X, y, max_iters=10000, W=W, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJBlEtnoVD3",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can see how well we did!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCmPEtoamaPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o = tf_h(X, W).numpy().T\n",
        "for i in range(10):\n",
        "  print('No: {}'.format(i+1), '\\tTarget: {}'.format(ds_arr[-1, i]), '\\tPredicted: {}'.format(o[0, i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9YpnSICmvtT",
        "colab_type": "text"
      },
      "source": [
        "## Method 2\n",
        "In this method we do a little **preprocess**. We first **normalize** the dataset. This help faster convergence.\n",
        "\n",
        "Other steps are just like *method 1*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qQm6Q-vZAVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(ds):\n",
        "  mean = np.array(ds.mean())\n",
        "  mean = mean[np.newaxis, :]\n",
        "  std = np.array(ds.std())\n",
        "  std = std[np.newaxis, :]\n",
        "  X = np.array(ds)\n",
        "  X = (X-mean)/std\n",
        "  return X\n",
        "\n",
        "def invert(X, ds):\n",
        "  mean = np.array(ds.mean())\n",
        "  mean = mean[np.newaxis, :]\n",
        "  std = np.array(ds.std())\n",
        "  std = std[np.newaxis, :]\n",
        "  X = (X*std) + mean\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmJUEGYgUxxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_arr = np.transpose(np.array(ds))\n",
        "normalized_ds_arr = np.transpose(normalize(ds))\n",
        "y = normalized_ds_arr[-1:, :]\n",
        "X = normalized_ds_arr[:-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJvL5M6DV2LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.constant(X, dtype=tf.float32)\n",
        "y = tf.constant(y, dtype=tf.float32)\n",
        "W = tf.Variable(np.random.rand(X.shape[0]+1, 1), dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LvuMuyAWQUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf_train(X, y, max_iters=10000, W=W, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0yab8m9acwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.array(ds.mean())\n",
        "mean = mean[np.newaxis, :]\n",
        "std = np.array(ds.std())\n",
        "std = std[np.newaxis, :]\n",
        "o = tf_h(X, W).numpy().T\n",
        "o = (o*std[0,-1])+mean[0,-1]\n",
        "for i in range(10):\n",
        "  print('No: {}'.format(i+1), '\\tTarget: {}'.format(ds_arr[-1, i]), '\\tPredicted: {}'.format(o[0, i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB8Myz0XnXMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}