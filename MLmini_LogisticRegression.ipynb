{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLmini-LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwuUixfnGfzTySn1s2bphn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearningMiniCourse/blob/master/MLmini_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOz2-2BTKSJG",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *mini* Course\n",
        "### PythonChallenge.ir\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "\n",
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdVQTDWntkM0",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The theoretical stuff has been discussed in the video lectures. Let's implement a little...\n",
        "\n",
        "First of all, we should import some modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGuG9on8KIGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6OLgydb7yBK",
        "colab_type": "text"
      },
      "source": [
        "# Discovering Sigmoid\n",
        "Let's see **sigmoid** function in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95o_uqNF75jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "xs = [i for i in np.arange(-10, 10, 0.5)]\n",
        "ys = [sigmoid(x) for x in xs]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xs, ys, 'r-')\n",
        "plt.title(r'Sigmoid Function: $\\frac{1}{1+e^{-x}}$')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('$\\sigma(x)$')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WtijAvtqcv",
        "colab_type": "text"
      },
      "source": [
        "# Importing Dataset\n",
        "Today, we'll be using **graduate admission** dataset. It predicts the likelihood of being accepted in a graduate program. Let's import it in our program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmHZPXuWKgHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip graduate\\-admissions.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0fIIK8FL7ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = pd.read_csv('Admission_Predict.csv')\n",
        "ds = ds.drop('Serial No.', 1)\n",
        "ds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjd0KwLvQku3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_arr = np.array(ds)\n",
        "print(ds_arr.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IJsGhm57QpL",
        "colab_type": "text"
      },
      "source": [
        "# Normalization\n",
        "As discussed in the previous lecture, normalization helps a lot!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5GZhyeQhykW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(ds):\n",
        "  mean = np.array(ds.mean())\n",
        "  mean = mean[np.newaxis, :]\n",
        "  std = np.array(ds.std())\n",
        "  std = std[np.newaxis, :]\n",
        "  X = np.array(ds)\n",
        "  X = (X-mean)/std\n",
        "  return X\n",
        "\n",
        "def invert(X, ds):\n",
        "  mean = np.array(ds.mean())\n",
        "  mean = mean[np.newaxis, :]\n",
        "  std = np.array(ds.std())\n",
        "  std = std[np.newaxis, :]\n",
        "  X = (X*std) + mean\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dUWArjBh1J-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_ds_arr = normalize(ds)\n",
        "x = normalized_ds_arr[:, :-1]\n",
        "y = normalized_ds_arr[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l177vmFB7ZeN",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Codes\n",
        "Our implementation in tensorflow is much like the previous session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuWzgyJ7Q7yK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.constant(x, dtype=tf.float32)\n",
        "Y = tf.constant(y, dtype=tf.float32)\n",
        "\n",
        "w = tf.Variable(np.random.rand(X.shape[1]+1, 1), dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVjLdquVOCn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def h(x, w):\n",
        "  x = tf.concat((tf.ones((x.shape[0], 1)), x), axis=1)\n",
        "  return tf.sigmoid(tf.matmul(x,w))\n",
        "\n",
        "def cost(x, y, w):\n",
        "  return tf.reduce_mean(tf.losses.binary_crossentropy(y, h(x, w)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDrGNE9KMgai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "w = tf.Variable(np.random.rand(X.shape[1]+1, 1), dtype=tf.float32)\n",
        "\n",
        "def train_step(x, y, w, verbose=0):\n",
        "  with tf.GradientTape() as t:\n",
        "    J = cost(x, y, w)\n",
        "  if verbose:\n",
        "    print('Loss: {}'.format(J))\n",
        "  w_grads = t.gradient(J, w)\n",
        "  optimizer.apply_gradients(zip([w_grads], [w]))\n",
        "  return w\n",
        "\n",
        "print('Before: ', w)\n",
        "w = train_step(X[15:16, :], Y[15:16, :], w, verbose = 1)\n",
        "print('After: ', w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LRl5CbgVpLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, Y, max_iters=100, min_cost=0.01, w=None, verbose=0):\n",
        "  if w is None:\n",
        "    w = tf.Variable(np.random.rand(X.shape[1], 1), dtype=tf.float32)\n",
        "  for i in range(max_iters):\n",
        "    index = np.random.randint(0, X.shape[0])\n",
        "    w = train_step(X[index:index+1, :], Y[index:index+1, :], w)\n",
        "    if verbose:\n",
        "      print('Cost: ', cost(X, Y, w).numpy())\n",
        "  print(\"Training Done...\")\n",
        "  print(\"Cost: {}\".format(cost(X, Y, w).numpy()))\n",
        "  print(\"w = \", w)\n",
        "  return w\n",
        "\n",
        "w = train(X, Y, w=w, max_iters=1000, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D48ersedu_rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.array(ds.mean())\n",
        "mean = mean[np.newaxis, :]\n",
        "std = np.array(ds.std())\n",
        "std = std[np.newaxis, :]\n",
        "o = h(X, w).numpy()\n",
        "o = (o*std[0,-1])+mean[0,-1]\n",
        "for i in range(50):\n",
        "  print('No: {}'.format(i+1), '\\tTarget: {}'.format(ds_arr[i, -1]), '\\tPredicted: {}'.format(o[i, 0]))  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}